import psycopg2
import os
from dotenv import load_dotenv
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

def create_database():
    """Create the database if it doesn't exist"""
    try:
        # Connect to PostgreSQL server (not to a specific database)
        conn = psycopg2.connect(
            host="localhost",
            port="5432",
            user="postgres",
            password="0576"
        )
        conn.autocommit = True
        cursor = conn.cursor()
        
        # Check if database exists
        cursor.execute("SELECT 1 FROM pg_database WHERE datname = 'phix_hrms'")
        exists = cursor.fetchone()
        
        if not exists:
            logger.info("Creating database 'phix_hrms'...")
            cursor.execute("CREATE DATABASE phix_hrms")
            logger.info("‚úÖ Database 'phix_hrms' created successfully!")
        else:
            logger.info("‚úÖ Database 'phix_hrms' already exists!")
        
        cursor.close()
        conn.close()
        
    except Exception as e:
        logger.error(f"‚ùå Error creating database: {e}")
        return False
    
    return True

def run_migrations():
    """Run Alembic migrations"""
    try:
        logger.info("Running database migrations...")
        result = os.system("alembic upgrade head")
        if result == 0:
            logger.info("‚úÖ Migrations completed successfully!")
            return True
        else:
            logger.error(f"‚ùå Migration failed with exit code: {result}")
            return False
    except Exception as e:
        logger.error(f"‚ùå Error running migrations: {e}")
        return False

def create_performance_indexes():
    """Create database indexes for better performance"""
    try:
        logger.info("Creating performance indexes...")
        
        # Connect to the phix_hrms database
        conn = psycopg2.connect(
            host="localhost",
            port="5432",
            user="postgres",
            password="0576",
            database="phix_hrms"
        )
        conn.autocommit = True
        cursor = conn.cursor()
        
        # List of indexes to create
        indexes = [
            # Users table indexes
            "CREATE INDEX IF NOT EXISTS idx_users_email ON users(email)",
            "CREATE INDEX IF NOT EXISTS idx_users_google_id ON users(google_id)",
            "CREATE INDEX IF NOT EXISTS idx_users_facebook_id ON users(facebook_id)",
            "CREATE INDEX IF NOT EXISTS idx_users_apple_id ON users(apple_id)",
            "CREATE INDEX IF NOT EXISTS idx_users_is_active ON users(is_active)",
            "CREATE INDEX IF NOT EXISTS idx_users_created_at ON users(created_at)",
            
            # OTPs table indexes
            "CREATE INDEX IF NOT EXISTS idx_otps_email ON otps(email)",
            "CREATE INDEX IF NOT EXISTS idx_otps_email_expires ON otps(email, expires_at)",
            "CREATE INDEX IF NOT EXISTS idx_otps_is_used ON otps(is_used)",
            "CREATE INDEX IF NOT EXISTS idx_otps_created_at ON otps(created_at)",
            
            # Locations table indexes
            "CREATE INDEX IF NOT EXISTS idx_locations_name ON locations(name)",
            "CREATE INDEX IF NOT EXISTS idx_locations_code ON locations(code)",
            "CREATE INDEX IF NOT EXISTS idx_locations_is_deleted ON locations(is_deleted)",
            
            # Skills table indexes
            "CREATE INDEX IF NOT EXISTS idx_skills_name ON skills(name)",
            "CREATE INDEX IF NOT EXISTS idx_skills_is_deleted ON skills(is_deleted)",
            
            # User skills table indexes
            "CREATE INDEX IF NOT EXISTS idx_user_skills_user_id ON user_skills(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_user_skills_skill_id ON user_skills(skill_id)",
            
            # Companies table indexes
            "CREATE INDEX IF NOT EXISTS idx_companies_name ON companies(name)",
            "CREATE INDEX IF NOT EXISTS idx_companies_country ON companies(country)",
            "CREATE INDEX IF NOT EXISTS idx_companies_is_deleted ON companies(is_deleted)",
            
            # Education facilities table indexes
            "CREATE INDEX IF NOT EXISTS idx_education_facilities_name ON education_facilities(name)",
            "CREATE INDEX IF NOT EXISTS idx_education_facilities_country ON education_facilities(country)",
            "CREATE INDEX IF NOT EXISTS idx_education_facilities_is_deleted ON education_facilities(is_deleted)",
            
            # Certification centers table indexes
            "CREATE INDEX IF NOT EXISTS idx_certification_centers_name ON certification_centers(name)",
            "CREATE INDEX IF NOT EXISTS idx_certification_centers_is_deleted ON certification_centers(is_deleted)",
            
            # Projects table indexes
            "CREATE INDEX IF NOT EXISTS idx_projects_user_id ON projects(user_id)",
            "CREATE INDEX IF NOT EXISTS idx_projects_is_deleted ON projects(is_deleted)",
            
            # Project images table indexes
            "CREATE INDEX IF NOT EXISTS idx_project_images_project_id ON project_images(project_id)",
            
            # Composite indexes for better query performance
            "CREATE INDEX IF NOT EXISTS idx_users_email_active ON users(email, is_active)",
            "CREATE INDEX IF NOT EXISTS idx_otps_email_used_expires ON otps(email, is_used, expires_at)",
        ]
        
        # Execute each index creation
        for index_sql in indexes:
            try:
                cursor.execute(index_sql)
                logger.info(f"‚úÖ Created index: {index_sql.split('IF NOT EXISTS ')[1].split(' ON ')[0]}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Index creation failed: {e}")
        
        cursor.close()
        conn.close()
        logger.info("‚úÖ Performance indexes created successfully!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error creating indexes: {e}")
        return False

def optimize_database_settings():
    """Optimize PostgreSQL settings for better performance"""
    try:
        logger.info("Optimizing database settings...")
        
        conn = psycopg2.connect(
            host="localhost",
            port="5432",
            user="postgres",
            password="0576",
            database="phix_hrms"
        )
        conn.autocommit = True
        cursor = conn.cursor()
        
        # Database optimization settings
        optimizations = [
            "ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements'",
            "ALTER SYSTEM SET max_connections = 200",
            "ALTER SYSTEM SET shared_buffers = '256MB'",
            "ALTER SYSTEM SET effective_cache_size = '1GB'",
            "ALTER SYSTEM SET maintenance_work_mem = '64MB'",
            "ALTER SYSTEM SET checkpoint_completion_target = 0.9",
            "ALTER SYSTEM SET wal_buffers = '16MB'",
            "ALTER SYSTEM SET default_statistics_target = 100",
            "ALTER SYSTEM SET random_page_cost = 1.1",
            "ALTER SYSTEM SET work_mem = '4MB'",
            "ALTER SYSTEM SET min_wal_size = '1GB'",
            "ALTER SYSTEM SET max_wal_size = '4GB'",
        ]
        
        for optimization in optimizations:
            try:
                cursor.execute(optimization)
                logger.info(f"‚úÖ Applied optimization: {optimization.split('SET ')[1].split(' =')[0]}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Optimization failed: {e}")
        
        cursor.close()
        conn.close()
        logger.info("‚úÖ Database optimizations applied successfully!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error optimizing database: {e}")
        return False

def main():
    """Main setup function with optimizations"""
    logger.info("üöÄ Setting up Phix HRMS Database with optimizations...")
    logger.info("=" * 60)
    
    # Step 1: Create database
    if create_database():
        logger.info("\nüìä Database setup completed!")
    else:
        logger.error("\n‚ùå Database setup failed!")
        return
    
    # Step 2: Run migrations
    if run_migrations():
        logger.info("\nüîÑ Migration setup completed!")
    else:
        logger.error("\n‚ùå Migration setup failed!")
        return
    
    # Step 3: Create performance indexes
    if create_performance_indexes():
        logger.info("\n‚ö° Performance indexes created!")
    else:
        logger.warning("\n‚ö†Ô∏è Performance indexes creation failed!")
    
    # Step 4: Optimize database settings
    if optimize_database_settings():
        logger.info("\nüîß Database optimizations applied!")
    else:
        logger.warning("\n‚ö†Ô∏è Database optimizations failed!")
    
    logger.info("\nüéâ Database setup completed successfully!")
    logger.info("\nüìà Performance optimizations applied:")
    logger.info("   ‚úÖ Increased connection pool size")
    logger.info("   ‚úÖ Added database indexes")
    logger.info("   ‚úÖ Optimized PostgreSQL settings")
    logger.info("   ‚úÖ Batch operations for data import")
    logger.info("   ‚úÖ Async email operations")
    logger.info("   ‚úÖ Performance monitoring middleware")
    
    logger.info("\nYou can now run the application with:")
    logger.info("python -m uvicorn app.main:app --reload")

if __name__ == "__main__":
    main() 